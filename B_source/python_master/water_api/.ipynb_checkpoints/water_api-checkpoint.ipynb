{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from modules import connection as cn ,apiurl as au\n",
    "from modules.dataprocess import DataProcess\n",
    "from bs4 import BeautifulSoup\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd\n",
    "import glob\n",
    "import datetime\n",
    "\n",
    "path = \"/home/hadoop/data/leeys/water_data/\"\n",
    "\n",
    "#year=sys.argv[1]\n",
    "#if(len(sys.argv!=1)):\n",
    "#    print(\"1개더 쓰세요\")\n",
    "#    sys.exit()\n",
    "year=2019\n",
    "    \n",
    "#지역정보를 가져옴\n",
    "api_url=au.crop_kwater_url(1)\n",
    "soup=cn.getSoup(api_url)\n",
    "dp=DataProcess()\n",
    "sido=[]\n",
    "for item in soup.find_all(\"sido\"):\n",
    "    sido.append(item.text)\n",
    "sido=['충남', '전남']\n",
    "    \n",
    "#지반종류 가져옴\n",
    "api_url=au.crop_kwater_url(2)\n",
    "soup=cn.getSoup(api_url)\n",
    "wellnum=[]\n",
    "for item in soup.find_all(\"code\"):\n",
    "    wellnum.append(item.text)\n",
    "\n",
    "#년도 정보를 가져옴\n",
    "#api_url=au.crop_kwater_url(4)\n",
    "#soup=cn.getSoup(api_url)\n",
    "#year=[]\n",
    "#for item in soup.find_all(\"yyyy\"):\n",
    "#    year.append(item.text)\n",
    "    \n",
    "#상세 지역정보를 가져옴\n",
    "api_url=au.crop_kwater_url(3,sido,wellnum)\n",
    "jewon={}\n",
    "for key, value in api_url.items():\n",
    "    soup=cn.getSoup(key)\n",
    "    for item in soup.find_all(\"wnumno\"):\n",
    "        wnumno=item.text\n",
    "        jewon[wnumno]=value\n",
    "\n",
    "#최종 지하수 정보       \n",
    "api_url=au.crop_kwater_url(5,year,jewon)\n",
    "data=[]\n",
    "dp=DataProcess()\n",
    "for api_url1, do in api_url.items():\n",
    "    soup=cn.getSoup(api_url1)\n",
    "    for item in soup.find_all(\"item\"):\n",
    "        row={}\n",
    "        for ele in item:\n",
    "            row.update({ele.name:ele.text.split(\" \")[0]})\n",
    "            row.update({\"do\":do})\n",
    "        data.append(row)\n",
    "    if len(data)!=0:\n",
    "        dp.setDataList(data)\n",
    "    else:\n",
    "        print(\"no data to fetch!\")\n",
    "    dp.writeToCsv()\n",
    "\n",
    "#폴더에 있는 모든 주소를 불러옴\n",
    "#df=pd.DataFrame(data)\n",
    "file_list = glob.glob(path+\"*\")\n",
    "file_list_csv = [file for file in file_list if file.endswith(\".csv\")]\n",
    "\n",
    "#데이터를 하나로 만듬\n",
    "df1=[]\n",
    "for file_name in file_list_csv:\n",
    "    df2=pd.read_csv(file_name, encoding='utf-8')\n",
    "    df1.append(df2)\n",
    "data=pd.concat(df1, ignore_index=True)\n",
    "data=data.drop(data.columns[[0]], axis='columns')\n",
    "data=data.drop_duplicates()\n",
    "\n",
    "#컬럼을 만들어줌\n",
    "data[\"year\"]=data['testymd'].str[:4]\n",
    "data[\"month\"]=data['testymd'].str[5:7]\n",
    "data[\"si\"]=data['obsvname'].str[:2]\n",
    "\n",
    "data['year_month']=data['year']+'_'+data['month']\n",
    "data.set_index(\"year_month\")\n",
    "data1=data[data[\"si\"]=='천안']\n",
    "data2=data[data[\"si\"]=='나주']\n",
    "data1.set_index(\"watnum\")\n",
    "data2.set_index(\"watnum\")\n",
    "data2=data2.drop_duplicates(['year_month'], keep='first')\n",
    "data1=data1.drop_duplicates(['year_month'], keep='first')\n",
    "data1 = data1.sort_values([\"year_month\"], ascending=[False])\n",
    "data2 = data2.sort_values([\"year_month\"], ascending=[False])\n",
    "\n",
    "y_m_l=[str(x)+'_'+str(y).zfill(2)  for x in range(1990,2019) for y in range(1,13)]\n",
    "\n",
    "for x in y_m_l:\n",
    "    if x not in list(data1[\"year_month\"]):\n",
    "        data1.loc[x, 'year_month'] = x\n",
    "    if x in list(data1[\"year_month\"]):\n",
    "        data1.loc[x] = data1[(data1[\"year_month\"]==x)].values[0]   \n",
    "        \n",
    "data1=data1.drop_duplicates(['year_month'], keep='last')\n",
    "\n",
    "for x in y_m_l:\n",
    "    if x not in list(data2[\"year_month\"]):\n",
    "        data2.loc[x, 'year_month'] = x\n",
    "    if x in list(data2[\"year_month\"]):\n",
    "        data2.loc[x] = data2[(data2[\"year_month\"]==x)].values[0]   \n",
    "        \n",
    "data2=data2.drop_duplicates(['year_month'], keep='last')\n",
    "\n",
    "#저장하기\n",
    "\n",
    "data1.to_csv(path+\"water_data_cheonan\"+str(datetime.datetime.now()).split(\".\")[0].replace(\":\",\"-\")+\".csv\")\n",
    "data2.to_csv(path+\"water_data_naju\"+str(datetime.datetime.now()).split(\".\")[0].replace(\":\",\"-\")+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
